{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e027d5-fe8e-49f1-933a-a30ee924d8f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modified MetaDistil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c183151-5afa-46fd-a329-9c7479607d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1deb75-4314-4c7c-881c-35f62e7e5c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Choosing our \"teacher\" and \"student\" models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e389925-6ad7-4ecd-97bc-3741ce578f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "student = \"distilbert-base-uncased\"\n",
    "teacher = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136627a4-226b-4e51-a4f8-3c3a1d56ea11",
   "metadata": {
    "id": "Mxo4XGgRgQhO",
    "tags": []
   },
   "source": [
    "## 1. Loading our SST-2 part of the GLUE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf72c3e-4156-433a-a227-7fc4ddb3cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/abhin/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7c7b8708b6470b87e764df28e6ad3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\", split=[\"train[:30000]\", \"train[30000:30100]\", \"validation\", \"train[60000:62000]\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea7153f-c0e6-4363-a066-7385898b08a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 30000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 100\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 872\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['sentence', 'label', 'idx'],\n",
       "     num_rows: 2000\n",
       " })]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11329d9b-59d1-4084-889f-4a06b5756bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b87d7f-1062-4cc2-9046-7fae971e0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = DatasetDict({\n",
    "    \"train\": raw_datasets[0],\n",
    "    \"quiz\": raw_datasets[1],\n",
    "    \"validation\": raw_datasets[2],\n",
    "    \"test\": raw_datasets[3]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5355e4bd-ec39-4dd1-8641-0111a6cbc0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    quiz: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95cfe3dc-538b-433f-a8c8-a0bbd8552cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283734ad-9c35-4ac5-8609-3f6b560a92ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"that 's far too tragic to merit such superficial treatment \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[5]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25745c1a-55fe-4598-9e00-18980e6a28f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[5]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e9a563-8da7-4aa6-87dd-4dad28a679a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset[5]['idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b6283b-e93e-4602-9632-3e9907bc642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b50079-2e8a-4ee0-94f0-0d90324b26c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb09b423-063d-43e3-bd3a-5a7b4a972acc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c411f583-ab52-4744-a918-195581482893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\abhin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-7ee44344b2e13c1a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\abhin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-ca9296800043200a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\abhin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-5b0467daaa65b6a1.arrow\n",
      "Loading cached processed dataset at C:\\Users\\abhin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-eb58b859a3e8c393.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    quiz: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b8aa8-88b3-462b-83bb-9ea95d9c7685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d388056-60db-4809-a926-26af3b882f26",
   "metadata": {},
   "source": [
    "## 3. Preparing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee4c9de-7ad4-4dc5-9b62-ba750628fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073e0380-d0cf-4229-972a-fde3d7cfae8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37ae75b-5f36-45d4-a265-bef0a9508449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=64, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "quiz_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"quiz\"], shuffle=True, batch_size=64, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], batch_size=20, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=128, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "befa0680-bc15-4807-a23a-0a5d2406f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([64]),\n",
       " 'input_ids': torch.Size([64, 44]),\n",
       " 'attention_mask': torch.Size([64, 44])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42500b26-7860-427e-87f2-23b8db960163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03af92f0-afa5-469d-b498-5ef0359c864a",
   "metadata": {},
   "source": [
    "## 4. Loading \"teacher\" and \"student\" models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a2b8a7-ae26-4079-af2f-32adf0cb5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2label, label2id dicts for the outputs for the model\n",
    "labels = tokenized_datasets[\"train\"].features[\"labels\"].names\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7d3552-67d5-4103-a21b-b1c46941a85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# teacher model\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# student model\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "930bacef-6d0b-4e56-977c-9ed6c5c2125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "best_teacher_weight = torch.load('./teacher-best_weight/bert-base-uncased-SST-2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187f6907-6cef-4e07-91a3-8c4255e512c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.load_state_dict(best_teacher_weight['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3f57d59-8f5f-4a33-be1d-44fb73ca837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0010, grad_fn=<NllLossBackward0>) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = teacher_model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9737251a-be2e-4af0-90dd-2a899b22d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6924, grad_fn=<NllLossBackward0>) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = student_model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7617e6-958c-4461-989e-3e3995d90a40",
   "metadata": {},
   "source": [
    "## 5. Training Student with Distillation for One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "930cff1b-96c2-4f95-bfcd-b0a44b50365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "teacher_optimizer = AdamW(teacher_model.parameters(), lr=6e-5)\n",
    "student_optimizer = AdamW(student_model.parameters(), lr=6e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90f353b9-16d6-4a88-bc97-398df98162a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "from train_eval_func import set_lr_scheduler\n",
    "\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "student_lr_scheduler = set_lr_scheduler(\n",
    "    optimizer          = student_optimizer,\n",
    "    num_training_steps = num_training_steps\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d46bc5b6-9404-4074-b5cf-5904b4d9380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f1db2a2-f42b-43d7-84bb-aa5f06512fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_eval_func import eval_loop, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6dbe6-7415-4d26-b083-6b3f7cfb70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import evaluate\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "temperature = 4\n",
    "alpha = 0.5\n",
    "n_batches = len(train_dataloader)\n",
    "\n",
    "ft_train_loss = None\n",
    "ft_train_acc  = None\n",
    "ft_val_loss   = None\n",
    "\n",
    "model.train()\n",
    "train_start = time.time() \n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for b, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs    = model(**batch)\n",
    "        loss       = outputs.loss\n",
    "        total_loss += float(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        logits  = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    #### training loss and accuracy \n",
    "    avg_train_loss = total_loss / n_batches\n",
    "    train_acc      = accuracy_metric.compute()\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accs.append(train_acc['accuracy'])\n",
    "    \n",
    "    #### validation training loss and accuracy \n",
    "    val_acc, val_loss = eval_loop(model, val_dataloader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc['accuracy'])\n",
    "    \n",
    "    #### Display metrics\n",
    "    print(\"<-----------------\", \"Epoch\", epoch + 1, \"----------------->\")\n",
    "    print(f\"Loss: {round(avg_train_loss, 2)}, Accuracy: {train_acc['accuracy']}\")\n",
    "    print(f\"Validation Loss: {round(val_loss, 2)}, Validation Accuracy: {val_acc['accuracy']}\")\n",
    "    \n",
    "    total_time_per_epoch = time.time() - start\n",
    "    print(\"Elapsed Time:\", round(total_time_per_epoch, 4), \"sec\") \n",
    "    time_per_epoch_hist.append(total_time_per_epoch)\n",
    "    \n",
    "    #### Check early stopping\n",
    "    if earlyStopping.checkCondition(val_loss):\n",
    "        print(\">>>>> Early stoppping callback <<<<<\")\n",
    "        break\n",
    "\n",
    "ft_total_train_time = time.time() - train_start\n",
    "print(\"Total Training Time:\", total_train_time, \"sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
